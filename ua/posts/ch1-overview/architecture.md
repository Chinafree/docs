### 1.2 Загальна архітектура

WebMagic структуровані в `Downloader`,` PageProcessor`, `Scheduler`,` Pipeline` чотири компонента павуком організовує їх один з одним. Цей компонент відповідає можливостям чотирьох гусеничний життєвим циклом завантаження, обробки, управління, і наполегливість. WebMagic дизайн посилання Scapy, але реалізація деяких з більш Java.

Павук буде кілька компонентів, щоб організувати себе так, щоб вони могли взаємодіяти один з одним, процес реалізації може розглядатися павук великий контейнер, також логіка ядро ​​WebMagic.

WebMagic загальна архітектура виглядає наступним чином:

![image](http://code4craft.github.io/images/posts/webmagic.png)

### 1.2.1 чотири компонента WebMagic

#### 1.Downloader

Downloader відповідає за завантаження з Інтернет-сторінки, для подальшої обробки. WebMagic за замовчуванням [Apache HttpClient](http://hc.apache.org/index.html) як інструмент завантаження.

#### 2.PageProcessor

PageProcessor відповідає за аналіз сторінки, витягувати корисну інформацію, а також відкриття нових посилань. WebMagic використовувати [Jsoup](http://jsoup.org/) в якості синтаксичного аналізу інструментів HTML, на основі його розробки аналітичного інструменту XPath [Xsoup](https://github.com/code4craft/xsoup).

У цих чотирьох компонентів, `PageProcessor` не те ж саме для кожної сторінки кожного сайту, користувач повинен налаштувати частин.

#### 3.Scheduler

URL планувальника вдається просканувати, а також деякі важко працювати. WebMagic надається за замовчуванням JDK URL черзі управління пам'яттю, а також встановити, щоб піти з вагою. Redis також підтримує використання розподіленого управління.

Якщо проект не розподілила деякі особливі потреби, вам не потрібно, щоб налаштувати свій власний планувальник.

#### 4.Pipeline

Обробка трубопроводу відповідає за прийняття результатів, включаючи розрахунки, зберігалися в файли, бази даних і так далі. WebMagic надається за замовчуванням "на консоль" і програми лікування "Зберегти в файл" два результату.

`Pipeline` визначає спосіб збереження результатів, якщо ви хочете зберегти у зазначеній базі даних, вам потрібно написати відповідний трубопровід. Для класу, як правило потрібно тільки написати `Pipeline`.

### 1.2.2 для об'єктів передачі даних

#### 1. Запит

`Request` є шаром пакет URL-адресу, запит відповідного адреси URL.

Він є носієм PageProcessor взаємодіяти з Downloader, Downloader це єдиний спосіб PageProcessor контролю.

На додаток до самого URL, він містить ключ-значення Структура поля `extra`. Ви можете зберегти деякі додаткові спеціальні атрибути, а потім прочитати в інших місцях для виконання різних функцій. Наприклад, деяка додаткова інформація на одній сторінці і так далі.

#### 2. Сторінка

`Page` представники Downloader для завантаження сторінки - може бути HTML, він може бути зміст JSON або інших текстових форматів.

Процес екстракції Сторінка WebMagic є ядром об'єкта, який забезпечує способи видобутку, зберегти результати і так далі. У разі четвертому розділі, ми будемо детально її використання.

#### 3. ReusltItems

`ReusltItems` еквівалентно карті, яка проводить обробку результатів PageProcessor для трубопроводу використання. Карта і його API дуже схожий, варто відзначити, що він має поле `skip`, якщо встановлено вірно, трубопровід не повинен бути оброблений.

### 1.2.3 --spider гусеничний двигун працює

Павук є ядром WebMagic внутрішні процеси. Властивість Downloader, PageProcessor, планувальник, трубопроводів є павук, ці властивості можуть бути вільно встановлені шляхом установки цієї властивості можуть виконувати різні функції. Павук WebMagic також працюють вхід, який інкапсулює створення пошукових роботів, запускати, зупиняти, можливості многопоточности. Ось набір кожного компонента, і подавав приклад многопоточности і запуску. Детальна павук налаштування Глава 4 - [crawler configuration, start and stop](../ch4-basic-page-processor/spider-config.html).

```java
public static void main(String[] args) {
    Spider.create(new GithubRepoPageProcessor())
            // From https://github.com/code4craft began to grasp    
            .addUrl("https://github.com/code4craft")
            // Set the Scheduler, use Redis to manage URL queue
            .setScheduler(new RedisScheduler("localhost"))
            // Set Pipeline, will result in json way to save a file
            .addPipeline(new JsonFilePipeline("D:\\data\\webmagic"))
            //Open 5 simultaneous execution threads
            .thread(5)
            //Start crawler
            .run();
}
```

### 1.2.4 Швидкий старт

Багато з компонентів, описаних вище, але насправді користувач повинен бути стурбований не так багато, тому що велика частина модуля WebMagic вже забезпечує реалізацію за замовчуванням.

Загалом, для отримання гусеничному, `PageProcessor` є частиною необхідності писати, і` Spider` створюється і контрольовані вхідні сканерів. У четвертому розділі ми розповімо, як писати шукач налаштований PageProcessr, і Павук, щоб почати.
