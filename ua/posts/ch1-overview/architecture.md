### 1.2 Загальна архітектура

Чотири компонента пошукача WebMagic структуровані в `Downloader`,` PageProcessor`, `Scheduler`,` Pipeline` контактують поміж собою. Ці компоненти відповідають чотирьом здатність життєвого циклу пошукача: завантаження, обробки, управління і здатність зберігання. Архітектура WebMagic подібна до `Scapy`, але реалізована на `Java`.

Пошукач має кілька компонентів, але організованих таким чином, щоб вони могли взаємодіяти один з одним, процес реалізації можна розглядатити пошукач, як великий контейнер з логіка у ядрі ​​WebMagic.

Загальна архітектура WebMagic виглядає наступним чином:

![image](http://code4craft.github.io/images/posts/webmagic.png)

### 1.2.1 чотири компонента WebMagic

#### 1.Downloader завантажувач

Downloader відповідає за завантаження з Інтернет-сторінки, для подальшої обробки. У WebMagic за замовчуванням інструмент завантаження - [Apache HttpClient](http://hc.apache.org/index.html).

#### 2.PageProcessor аналіз сторінки

PageProcessor відповідає за аналіз сторінки, витягувати корисну інформацію, а також відкриття нових посилань. WebMagic використовувати [Jsoup](http://jsoup.org/) в якості синтаксичного аналізу інструментів HTML, на основі його розробки аналітичного інструменту XPath [Xsoup](https://github.com/code4craft/xsoup).

З цих чотирьох компонентів, тільки `PageProcessor` не той самий для кожної сторінки для кожного сайту, цю частину користувач повинен налаштувати.

#### 3.Scheduler планувальник

Менеджер планувальника Scheduler буде давати завдання сканувати URL по черзі. WebMagic за замовчуванням від JDK використовує менеджер черги URL-ів у пам'яті `memory queue management`, та може встановлювати пріоритети. Також підтримує використання розподіленого управління через Redis.

Якщо проект має деякі особливі потреби, що не бóли реалізовіні, тоді зможете налаштувати свій власний планувальник Scheduler.

#### 4.Pipeline конвеєрне збереження даних

Конвеєрна обробка даних Pipeline відповідає за прийняття результатів, включаючи перерахунки, зберігання в файли, у бази даних і так далі. WebMagic надається за замовчуванням "на консоль" і другий спосіб у програмі "Зберегти в файл" результат.

`Pipeline` визначає спосіб збереження результатів, якщо ви хочете зберегти у визначеній базі даних, тоді потрібно написати відповідну обробку даних. Як правило потрібно тільки написати `Pipeline`.

### 1.2.2 для об'єктів передачі даних

#### 1. Запит `Request`

`Request` є шаром пакет URL-адресу, запит відповідного адреси URL.

Він є носієм PageProcessor взаємодіяти з Downloader, Downloader це єдиний спосіб PageProcessor контролю.

На додаток до самого URL, він містить ключ-значення Структура поля `extra`. Ви можете зберегти деякі додаткові спеціальні атрибути, а потім прочитати в інших місцях для виконання різних функцій. Наприклад, деяка додаткова інформація на одній сторінці і так далі.

#### 2. Сторінка

`Page` представники Downloader для завантаження сторінки - може бути HTML, він може бути зміст JSON або інших текстових форматів.

Процес екстракції Сторінка WebMagic є ядром об'єкта, який забезпечує способи видобутку, зберегти результати і так далі. У разі четвертому розділі, ми будемо детально її використання.

#### 3. ReusltItems

`ReusltItems` еквівалентно карті, яка проводить обробку результатів PageProcessor для трубопроводу використання. Карта і його API дуже схожий, варто відзначити, що він має поле `skip`, якщо встановлено вірно, трубопровід не повинен бути оброблений.

### 1.2.3 --spider гусеничний двигун працює

Павук є ядром WebMagic внутрішні процеси. Властивість Downloader, PageProcessor, планувальник, трубопроводів є павук, ці властивості можуть бути вільно встановлені шляхом установки цієї властивості можуть виконувати різні функції. Павук WebMagic також працюють вхід, який інкапсулює створення пошукових роботів, запускати, зупиняти, можливості многопоточности. Ось набір кожного компонента, і подавав приклад многопоточности і запуску. Детальна павук налаштування Глава 4 - [crawler configuration, start and stop](../ch4-basic-page-processor/spider-config.html).

```java
public static void main(String[] args) {
    Spider.create(new GithubRepoPageProcessor())
            // From https://github.com/code4craft began to grasp    
            .addUrl("https://github.com/code4craft")
            // Set the Scheduler, use Redis to manage URL queue
            .setScheduler(new RedisScheduler("localhost"))
            // Set Pipeline, will result in json way to save a file
            .addPipeline(new JsonFilePipeline("D:\\data\\webmagic"))
            //Open 5 simultaneous execution threads
            .thread(5)
            //Start crawler
            .run();
}
```

### 1.2.4 Швидкий старт

Багато з компонентів, описаних вище, але насправді користувач повинен бути стурбований не так багато, тому що велика частина модуля WebMagic вже забезпечує реалізацію за замовчуванням.

Загалом, для отримання гусеничному, `PageProcessor` є частиною необхідності писати, і` Spider` створюється і контрольовані вхідні сканерів. У четвертому розділі ми розповімо, як писати шукач налаштований PageProcessr, і Павук, щоб почати.
